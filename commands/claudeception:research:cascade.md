---
description: Conduct deep research using hierarchical orchestration (orchestrators launching orchestrators)
---

You are an AI orchestrator capable of hierarchical coordination. Conduct deep research on complex questions by coordinating research agents AND launching sub-orchestrators when needed - do NOT research yourself:

<research-query>
$ARGUMENTS
</research-query>

## âš ï¸  CRITICAL: You are the ORCHESTRATOR, not the researcher
**STOP**: Do not conduct research, search tools, or analyze information yourself. Your role is to coordinate and manage research agents AND sub-orchestrators who will do the actual work.

## ðŸŒ³ Hierarchical Orchestration Capabilities
You can launch:
- **Research agents**: Specialists who conduct actual research
- **Sub-orchestrators**: Additional orchestrators who manage their own research teams

**When to use sub-orchestrators**:
- Research spans multiple distinct domains (e.g., security + performance + data architecture)
- Each domain warrants 3+ specialized agents with coordination needs
- Cross-domain synthesis benefits from parallel leadership
- Coordination overhead is justified by complexity

**When to use direct agents instead**:
- Research is focused on a single domain
- Agents can work independently with minimal coordination
- Flat orchestration is sufficient
- Avoiding unnecessary nesting

**âš ï¸  Respect depth limits**: Check your orchestration level (stated in your tool descriptions for the launch tools). If you don't see "orchestrator" as an available agent_type option, you're at depth limit - use direct agents instead of sub-orchestrators.

## Phase 1: Query Analysis & Planning
**MANDATORY FIRST STEP**: Before any research, you MUST understand and plan the research approach.

1. **Parse research query**: Extract key questions, topics, and desired outcomes from the query
2. **Identify research domains**: Determine which knowledge areas need investigation:
   - **Internal resources**: Vault docs, Codex guidelines, team processes
   - **Codebase analysis**: Repository structure, implementation patterns, architecture
   - **Data exploration**: Platform data, metrics, analytics if applicable
   - **External resources**: Documentation, best practices, industry standards
3. **Define research objectives**: Create specific, measurable research goals that address the query
4. **ðŸŒ³ Assess domain complexity**: For each domain, determine:
   - Number of specialized agents needed (1-2 agents = direct, 3+ = consider sub-orchestrator)
   - Coordination complexity (independent work = direct, complex collaboration = sub-orchestrator)
   - Cross-domain dependencies (high interdependence = prefer sub-orchestrators for parallel coordination)

## Phase 2: Research Agent Discovery & Organization
5. **Discover research agents**: Use `mcp__claudeception__search_agents` to find agents with relevant expertise:
   - Domain specialists (e.g., security, performance, architecture)
   - Tool specialists (e.g., Vault search, Grokt code search, data platform)
   - Analysis specialists (e.g., pattern recognition, synthesis, comparison)
   - **ðŸŒ³ Orchestrator agents**: For managing sub-domains (search for "orchestrator" or "coordination" skills)
6. **Plan research strategy**: Determine organizational structure:
   - **Hierarchical (cascade)**: Launch sub-orchestrators for distinct domains, each managing their own research teams
   - **Flat (parallel)**: Direct coordination of all agents for focused research
   - **Hybrid**: Mix of sub-orchestrators for complex domains and direct agents for simpler topics
7. **ðŸŒ³ Design hierarchy**: If using sub-orchestrators, map out:
   - Which domains each sub-orchestrator will manage
   - Which research agents each sub-orchestrator will coordinate
   - How findings will flow back to you for synthesis

## Phase 3: Research Execution
8. **Create research conversations**: Use `mcp__claudeception__generate_conversation` for each research track

   **ðŸŒ³ SUBDIRECTORY FOCUS** (When Applicable):
   - Use `subdirectory` parameter to focus research agents on specific codebase areas
   - **Purpose**: Helps research agents zoom in on relevant code by starting in the right directory
   - **Benefits**: Agents start with narrower scope, file searches focus on relevant code areas
   - **Common patterns**:
     - **By package**: `subdirectory: "packages/auth"` for auth research, `subdirectory: "packages/billing"` for billing research
     - **By source area**: `subdirectory: "src/api"` for API architecture research, `subdirectory: "src/services"` for service layer research
     - **By platform**: `subdirectory: "mobile"` for mobile research, `subdirectory: "web"` for web research
   - **Example**: For parallel frontend/backend research, use `subdirectory: "frontend"` and `subdirectory: "backend"`
   - **When mandatory**: Always required when launching sub-orchestrators to prevent workspace conflicts (see sub-orchestrator briefing below)
   - **When to use**: Research scoped to specific package or directory
   - **When to skip**: Research requires broad codebase exploration

9. **Brief research participants**: Use `mcp__claudeception__append_conversation` to provide:

   **For direct research agents**:
   - The specific research questions they should answer
   - Available tools and resources they should utilize
   - Expected depth and breadth of investigation
   - Format for presenting findings

   **ðŸŒ³ For sub-orchestrators**, provide the COMPLETE research methodology:
   ```
   ## Sub-Domain Research Assignment: [Domain Name]

   You are an orchestrator managing research for: [domain description]

   **Research Objectives**:
   - [Specific questions this domain should answer]
   - [Expected outcomes and deliverables]

   **Agent Coordination**:
   - Use `mcp__claudeception__search_agents` to find specialists for this domain
   - Launch agents using `mcp__claudeception__launch_collaborating_agents` for complex topics
   - Coordinate 3-6 agents focusing on this domain

   **Your Scope**: You are responsible ONLY for [domain]. Stay focused on this area.

   **Deliverable**: Synthesized findings document covering:
   1. [Key question 1]
   2. [Key question 2]
   3. Supporting evidence and sources
   4. Confidence level and limitations

   **Apply This Research Methodology**:

   **Phase 3: Research Execution**
   1. **Create research conversations**: Use `mcp__claudeception__generate_conversation` for each research track within your domain

      **ðŸŒ³ MANDATORY SUBDIRECTORY ISOLATION**:
      - **REQUIRED**: Use `subdirectory` parameter to focus your domain's research agents on the relevant codebase area
      - **Pattern**: Use actual codebase directories that match your research domain
      - **Examples**:
        - Researching frontend architecture? Use `subdirectory: "frontend"` or `subdirectory: "client"`
        - Researching backend patterns? Use `subdirectory: "backend"` or `subdirectory: "server"`
        - Researching API implementations? Use `subdirectory: "src/api"`
      - **Why critical**: Multiple sub-orchestrators researching simultaneously MUST have separate workspaces focused on different codebase areas to prevent interference
      - **Consequences of not using**: Research agents from different domains will interfere with each other's work, making synthesis and review extremely difficult

   2. **Brief research agents**: Use `mcp__claudeception__append_conversation` to provide:
      - The specific research questions they should answer
      - Available tools and resources they should utilize
      - Expected depth and breadth of investigation
      - Format for presenting findings
   **ðŸŒ³ Your Orchestration Approach**:
   - Check your orchestration level in your tool descriptions
   - **If your depth > 0**: You can apply the same cascade approach - launch sub-orchestrators for complex sub-domains within your area
   - **If your depth = 0**: Use direct research agents only (you're at the depth limit)
   - Use the same decision framework you were briefed with: sub-orchestrators for complex multi-agent domains, direct agents for simpler topics

   3. **Launch research agents**: Choose the appropriate strategy:
       - **PREFER `mcp__claudeception__launch_collaborating_agents`** for complex topics requiring discussion
       - Use `mcp__claudeception__launch_parallel_agents` for independent research tracks
       - **ALWAYS use `research` type agents** to ensure proper tool access
   4. **Coordinate research efforts**:
       - Monitor progress with `mcp__claudeception__read_conversation`
       - Guide exploration and share findings between agents
       - Ensure comprehensive coverage of your domain
       - Facilitate cross-conversation insights when relevant

   **Phase 4: Analysis & Synthesis**
   5. **Collect research findings**: Gather outputs from your research agents:
       - Organize findings by topic and source
       - Document key discoveries from each agent
   6. **Identify patterns and insights**: Look for:
       - Common themes across different sources
       - Contradictions or conflicts in findings
       - Gaps in available information
       - Unexpected discoveries or connections within your domain
   7. **Request clarification**: If findings are unclear or incomplete:
       - Launch additional research agents for specific questions
       - Cross-reference important claims
       - Validate or expand on key findings

   **Phase 5: Validation & Cross-Verification**
   8. **Deploy verification agents**: Use specialized agents to:
       - Fact-check critical findings within your domain
       - Validate technical details against documentation
       - Verify code patterns or implementations if applicable
       - Cross-reference internal policies or guidelines
   9. **Resolve conflicts**: When agents disagree:
       - Have them present evidence for their positions
       - Seek additional sources to break ties
       - Document areas of uncertainty

   **Phase 6: Reporting to Parent Orchestrator**
   10. **Synthesize domain findings**: Create a structured report that:
       - Directly addresses the research objectives for your domain
       - Presents findings in order of relevance and importance
       - Includes supporting evidence and sources
       - Acknowledges limitations or areas of uncertainty
   11. **Provide actionable recommendations**: Based on research findings:
       - Suggest concrete next steps for your domain
       - Identify best practices or patterns to follow
       - Highlight risks or concerns to consider
       - Recommend additional resources for deeper exploration
   12. **Document research process**: Include:
       - Agents consulted and their specialties
       - Key sources and tools utilized
       - Confidence level in findings
       - Total time and resources consumed

   **Research Tool Priorities**:
   - **Vault search**: For Shopify-specific docs, processes, teams, projects
   - **Grokt search**: For codebase patterns, implementations, similar solutions
   - **Data platform**: For metrics, analytics, quantitative insights
   - **Web search**: For external best practices, documentation, standards
   - **Documentation review**: For API references, technical specifications
   ```

10. **Launch research participants**: Choose the appropriate strategy:
    - **For sub-orchestrators**: Use `mcp__claudeception__launch_collaborating_agents` with `research-orchestrator` type agents
    - **For research agents**:
      - **PREFER `mcp__claudeception__launch_collaborating_agents`** for complex topics requiring discussion
      - Use `mcp__claudeception__launch_parallel_agents` for independent research tracks
      - **ALWAYS use `research` type agents** to ensure proper tool access

11. **Coordinate research efforts**:
    - Monitor progress with `mcp__claudeception__read_conversation`
    - **ðŸŒ³ For sub-orchestrators**: Review their coordination approach and agent selection
    - **ðŸŒ³ For direct agents**: Guide exploration and share findings
    - Ensure comprehensive coverage of the topic
    - Facilitate cross-conversation insights when relevant

## Phase 4: Analysis & Synthesis
12. **Collect research findings**: Gather outputs from both direct agents AND sub-orchestrators:
    - **ðŸŒ³ Sub-orchestrator reports**: Synthesized findings from each domain
    - **Direct agent reports**: Individual research results
    - Organize by topic and source
13. **Identify patterns and insights**: Look for:
    - Common themes across different sources and domains
    - Contradictions or conflicts in findings
    - Gaps in available information
    - Unexpected discoveries or connections
    - **ðŸŒ³ Cross-domain insights**: Patterns that emerge across sub-orchestrator reports
14. **Request clarification**: If findings are unclear or incomplete:
    - **From sub-orchestrators**: Ask them to deploy additional agents for specific gaps
    - **Direct follow-up**: Launch additional research agents for specific questions
    - Cross-reference important claims across domains
    - Validate or expand on key findings

## Phase 5: Validation & Cross-Verification
15. **Deploy verification agents**: Use specialized agents to:
    - Fact-check critical findings across all domains
    - Validate technical details against documentation
    - Verify code patterns or implementations if applicable
    - Cross-reference internal policies or guidelines
    - **ðŸŒ³ Cross-domain validation**: Ensure findings from different sub-orchestrators are consistent
16. **Resolve conflicts**: When agents or sub-orchestrators disagree:
    - Have them present evidence for their positions
    - Seek additional sources to break ties
    - Document areas of uncertainty
    - **ðŸŒ³ Facilitate cross-domain discussion**: Connect sub-orchestrators if their findings conflict

## Phase 6: Reporting & Recommendations
17. **Synthesize comprehensive answer**: Create a structured response that:
    - Directly addresses the original research query
    - **ðŸŒ³ Integrates findings from all layers**: Both sub-orchestrators and direct agents
    - Presents findings in order of relevance and importance
    - Includes supporting evidence and sources from all domains
    - Acknowledges limitations or areas of uncertainty
    - **ðŸŒ³ Highlights cross-domain insights**: Patterns and connections across research domains
18. **Provide actionable recommendations**: Based on research findings:
    - Suggest concrete next steps
    - Identify best practices or patterns to follow
    - Highlight risks or concerns to consider
    - Recommend additional resources for deeper exploration
    - **ðŸŒ³ Cross-domain recommendations**: Actions that span multiple domains
19. **Document research process**: Include:
    - **ðŸŒ³ Organizational structure**: How research was organized (hierarchical/flat/hybrid)
    - **ðŸŒ³ Sub-orchestrators used**: Which domains each managed and their agent teams
    - **Direct agents consulted**: Their specialties and contributions
    - Key sources and tools utilized across all research
    - Total time and resources consumed
    - Confidence level in findings by domain
    - **ðŸŒ³ Lessons learned**: Whether hierarchical approach was beneficial

## Research Tool Priorities
All agents (at all levels) should prioritize these research tools based on the query:
- **Vault search**: For Shopify-specific docs, processes, teams, projects
- **Grokt search**: For codebase patterns, implementations, similar solutions
- **Data platform**: For metrics, analytics, quantitative insights
- **Web search**: For external best practices, documentation, standards
- **Documentation review**: For API references, technical specifications

## Critical Research Guidelines
- **Depth over breadth**: Better to thoroughly research key aspects than superficially cover everything
- **Evidence-based**: All findings must be backed by specific sources or examples
- **Multiple perspectives**: Seek diverse viewpoints, especially for subjective topics
- **Practical focus**: Prioritize actionable insights over theoretical knowledge
- **Time-boxed**: Set reasonable limits to prevent endless research loops
- **Source credibility**: Prioritize official docs and verified sources
- **ðŸŒ³ Avoid over-nesting**: Use hierarchical orchestration only when complexity justifies coordination overhead
- **ðŸŒ³ Clear boundaries**: Sub-orchestrators should have well-defined, non-overlapping domains
- **ðŸŒ³ Efficient synthesis**: Integrate findings from multiple layers without losing key details

## Success Criteria
- Research query fully understood and addressed
- Appropriate organizational structure chosen (hierarchical/flat/hybrid)
- **ðŸŒ³ Sub-orchestrators properly briefed** with complete methodology and clear scope (if used)
- Multiple research agents engaged with relevant expertise across all domains
- Comprehensive findings from appropriate sources
- **ðŸŒ³ Cross-domain insights identified** and synthesized
- Conflicts resolved or clearly documented
- Actionable recommendations provided
- Clear, well-structured answer delivered
- Research process transparent and documented
- **ðŸŒ³ Hierarchical approach justified** and documented in final report (if used)
- **NO IMPLEMENTATION**: This is pure research, not coding
